{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdec43d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (8000, 4)\n",
      "y_train shape: (8000, 1)\n",
      "Sample X_train: [0.39443202 0.04491381 0.17939958 0.03346833]\n",
      "Sample y_train: [0.33817447]\n",
      "Processed data saved.\n",
      "Scalers saved.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os  # FIXED: Add import os for path joining\n",
    "\n",
    "# FIXED: Load merged df (from 01 – or re-load and merge here)\n",
    "PROJECT_ROOT = r\"D:\\Work\\Stress_Level_Prediction\\data\"\n",
    "TRAIN_TIME = os.path.join(PROJECT_ROOT, 'Train Data', 'Train Data Zip', 'time_domain_features_train.csv')\n",
    "TRAIN_FREQ = os.path.join(PROJECT_ROOT, 'Train Data', 'Train Data Zip', 'frequency_domain_features_train.csv')\n",
    "\n",
    "df_time = pd.read_csv(TRAIN_TIME)\n",
    "df_freq = pd.read_csv(TRAIN_FREQ)\n",
    "df = pd.merge(df_time, df_freq, on='uuid', how='inner')\n",
    "\n",
    "# Sample for faster training (optional – remove if you want full 369k)\n",
    "df = df.sample(n=10000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Feature engineering (example: daily_activity as SDRR + LF proxy for tasks)\n",
    "df['daily_activity'] = df['SDRR'] + df['LF']\n",
    "\n",
    "# UPDATED: Select features (HRV-based for sleep/activity/heart)\n",
    "features = ['MEAN_RR', 'SDRR', 'LF', 'HF']  # MEAN_RR for sleep, SDRR/LF/HF for heart/activity\n",
    "X = df[features]\n",
    "\n",
    "# Target: HR for regression (heart rate as stress indicator)\n",
    "y = df['HR'].values.reshape(-1, 1)\n",
    "\n",
    "# Scaling\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"Sample X_train: {X_train[0]}\")\n",
    "print(f\"Sample y_train: {y_train[0]}\")\n",
    "\n",
    "# Save processed\n",
    "df_processed = df[features + ['HR']].copy()\n",
    "df_processed.to_csv('../data/heart_stress_processed.csv', index=False)\n",
    "print(\"Processed data saved.\")\n",
    "\n",
    "# Save scalers\n",
    "import joblib\n",
    "joblib.dump(scaler_X, '../models/scaler_X.pkl')\n",
    "joblib.dump(scaler_y, '../models/scaler_y.pkl')\n",
    "print(\"Scalers saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
